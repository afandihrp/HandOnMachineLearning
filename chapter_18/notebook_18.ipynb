{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHKyOwvKvKqj"
      },
      "source": [
        "# Chapter 18: Reinforcement Learning\n",
        "\n",
        "**Based on \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition\" by Aurélien Géron**\n",
        "\n",
        "This notebook reproduces the code from Chapter 18 and provides theoretical explanations for each concept, as required by the individual task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLbtPN3mvKqn"
      },
      "source": [
        "## Chapter Summary\n",
        "\n",
        "This chapter introduces **Reinforcement Learning (RL)**, a distinct branch of machine learning where an **agent** learns to make optimal decisions by interacting with an **environment**.\n",
        "\n",
        "1.  **Core Concepts:** We start with the fundamental concepts of RL. The agent observes the environment, takes **actions**, and receives **rewards** (or penalties). The agent's goal is to learn a **policy** (a strategy) that maximizes its total expected reward over time. This involves the **credit assignment problem** (figuring out which actions led to a reward) and the use of a **discount factor (γ)** to value immediate rewards more than distant ones.\n",
        "\n",
        "2.  **Policy Search & Policy Gradients (PG):** The first major technique covered is **Policy Gradients**. Here, the agent's policy is a neural network that directly outputs action probabilities. The agent learns by running through episodes, calculating the advantage of each action (based on the total future discounted rewards, or **returns**), and then running a gradient descent step that *increases* the probability of actions that led to good returns and *decreases* the probability of actions that led to bad returns.\n",
        "\n",
        "3.  **Markov Decision Processes (MDPs):** To understand more advanced techniques, we explore the formal framework of MDPs. This involves states, actions, transition probabilities, and rewards. We learn about the **Bellman Optimality Equation**, which leads to algorithms like **Value Iteration** and **Q-Value Iteration** for finding the optimal policy when the environment's dynamics are known.\n",
        "\n",
        "4.  **Q-Learning:** For cases where the environment is unknown (the typical RL problem), we use **Q-Learning**. This is a **Temporal Difference (TD) learning** algorithm where the agent learns the optimal **Q-Value** (expected return) for every state-action pair by observing transitions and rewards as it explores the environment.\n",
        "\n",
        "5.  **Deep Q-Learning (DQN):** Q-Learning doesn't scale to problems with large state spaces (like video games). **Deep Q-Learning** solves this by using a deep neural network (a **DQN**) to *approximate* the Q-Values. This section also introduces two critical components for stabilizing training:\n",
        "    * **Experience Replay (Replay Buffer):** Stores the agent's experiences (state, action, reward, next_state) so it can train on random batches of past experiences, breaking temporal correlations.\n",
        "    * **Fixed Q-Value Targets:** Uses a separate **target model** to generate the target Q-Values, which stabilizes the training process by preventing the model from \"chasing its own tail.\"\n",
        "\n",
        "6.  **The TF-Agents Library:** We put all these concepts into practice using TF-Agents, Google's official library for Reinforcement Learning. We learn its components:\n",
        "    * **Environments:** How to wrap OpenAI Gym environments for use with TensorFlow.\n",
        "    * **Agents:** How to instantiate a `DqnAgent`.\n",
        "    * **Replay Buffers:** How to create a buffer to store experiences.\n",
        "    * **Drivers:** How to create a `DynamicStepDriver` to run the agent in the environment and collect experiences.\n",
        "    * **Training Loop:** How to build the full training pipeline to train an agent to play the Atari game Breakout.\n",
        "\n",
        "Finally, the chapter gives a brief overview of more advanced algorithms like Actor-Critic (A3C, A2C), PPO, and SAC, which form the basis of modern RL research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzCEWdSVvKqo"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the necessary libraries and set up our environment. We will need to install `gym` for the environments and `tf-agents` for the main RL library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dLR39RR2vKqp"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "# Update pip and setuptools first to avoid installation issues\n",
        "!{sys.executable} -m pip install -q -U pip setuptools\n",
        "# Install tensorflow and tensorflow-probability first, ensuring a compatible tensorflow version\n",
        "!{sys.executable} -m pip install -q -U tensorflow==2.19.0 tensorflow-probability\n",
        "# Install gymnasium and tf-agents. Removed 'gymnasium[atari]' and 'gymnasium[box2d]' due to installation errors.\n",
        "!{sys.executable} -m pip install -q -U gymnasium\n",
        "# The tf-agents library is currently encountering installation issues. Skipping for now.\n",
        "# !{sys.executable} -m pip install -q -U tf-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "uBuXda0VvKqq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import gymnasium as gym # Changed from 'gym'\n",
        "\n",
        "# Common imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# To get smooth animations\n",
        "import matplotlib.animation as animation\n",
        "mpl.rc('animation', html='jshtml')\n",
        "\n",
        "# A helper function to plot a gym environment\n",
        "def plot_environment(env, figsize=(5,4)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    # gymnasium render() returns the rgb_array directly when render_mode is set\n",
        "    img = env.render()\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xypGhEE9vKqq"
      },
      "source": [
        "## 1. Introduction to OpenAI Gym\n",
        "\n",
        "> **Theoretical Deep-Dive: The Agent-Environment Loop**\n",
        ">\n",
        "> Reinforcement Learning consists of an **agent** interacting with an **environment**. This interaction forms a loop:\n",
        "> 1.  The agent observes the environment's current **state** (or **observation**).\n",
        "> 2.  Based on this observation, the agent's **policy** chooses an **action**.\n",
        "> 3.  The agent performs the action, and the environment transitions to a new state.\n",
        "> 4.  The environment gives the agent a **reward** (a positive or negative number) for this transition.\n",
        "> 5.  The loop repeats. The agent's goal is to learn a policy that maximizes the total cumulative reward.\n",
        ">\n",
        "> **OpenAI Gym** is a toolkit that provides a wide variety of simulated environments (like Atari games, classic control problems, and robotics) with a standard API. This lets us build agents without having to build a new environment/simulator every time.\n",
        ">\n",
        "> The key Gym methods are:\n",
        "> -   `make(env_name)`: Creates an environment.\n",
        "> -   `reset()`: Resets the environment to its initial state and returns the first observation.\n",
        "> -   `step(action)`: Performs the given action and returns a tuple: `(observation, reward, done, info)`.\n",
        ">     -   `observation`: The new state of the environment.\n",
        ">     -   `reward`: The reward from the last action.\n",
        ">     -   `done`: A boolean that is `True` when the episode (e.g., the game) is over.\n",
        ">     -   `info`: A dictionary with extra, environment-specific information (we usually ignore this).\n",
        "> -   `render()`: Displays the environment (e.g., in a pop-up window).\n",
        "> -   `action_space`: The object that describes the set of possible actions (e.g., `Discrete(2)` for two discrete actions).\n",
        "> -   `observation_space`: The object that describes the shape and type of the observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "mqmfvyEbvKqr",
        "outputId": "66872617-a7e4-4062-db71-5bdf11af9a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Observation: [-0.01225074  0.0137057   0.00884442 -0.04202458]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create the CartPole environment, specifying render_mode for gymnasium\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "obs, info = env.reset()\n",
        "print(\"Initial Observation:\", obs)\n",
        "plot_environment(env);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1O5aASlvKqr",
        "outputId": "8df928a8-7bd2-4fde-c287-779bb157a8ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(2)\n",
            "Observation Space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
          ]
        }
      ],
      "source": [
        "print(\"Action Space:\", env.action_space)\n",
        "print(\"Observation Space:\", env.observation_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obHJP0OWvKqr",
        "outputId": "be01cd25-6239-4b2d-e720-8e1c6158557d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 42.186, Std: 8.717534284417813, Min: 24.0, Max: 67.0\n"
          ]
        }
      ],
      "source": [
        "# Hardcode a simple policy: accelerate left if pole leans left, right if pole leans right.\n",
        "def basic_policy(obs):\n",
        "    angle = obs[2]\n",
        "    return 0 if angle < 0 else 1\n",
        "\n",
        "# Run 500 episodes and see how long it lasts\n",
        "totals = []\n",
        "for episode in range(500):\n",
        "    episode_rewards = 0\n",
        "    obs, info = env.reset() # gymnasium reset returns (observation, info)\n",
        "    for step in range(200):\n",
        "        action = basic_policy(obs)\n",
        "        # gymnasium step returns (observation, reward, terminated, truncated, info)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        episode_rewards += reward\n",
        "        if terminated or truncated: # Check both terminated and truncated for episode end\n",
        "            break\n",
        "    totals.append(episode_rewards)\n",
        "\n",
        "print(f\"Mean: {np.mean(totals)}, Std: {np.std(totals)}, Min: {np.min(totals)}, Max: {np.max(totals)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He_EiZervKqs"
      },
      "source": [
        "This simple policy isn't great. The cart oscillates too much and the pole falls. We need a model that can learn a better strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWg-3oh4vKqs"
      },
      "source": [
        "## 2. Neural Network Policies (Policy Gradients)\n",
        "\n",
        "> **Theoretical Deep-Dive: Policy Gradients**\n",
        ">\n",
        "> A **policy** is a neural network that takes an observation as input and outputs action probabilities (a **stochastic policy**). We then *sample* an action from this probability distribution. This sampling allows the agent to **explore** new actions, rather than just **exploiting** the actions it already knows are good.\n",
        ">\n",
        "> But how do we train this network? We don't have target labels. We only have rewards, which are often delayed (e.g., you only win a game at the very end). This is the **credit assignment problem**.\n",
        ">\n",
        "> **Policy Gradients (PG)** solve this with three steps:\n",
        "> 1.  **Run & Collect:** Let the policy play the game for several full episodes and collect all observations, actions, and rewards.\n",
        "> 2.  **Evaluate Actions:** For every action taken, estimate how \"good\" it was. We do this by looking at all the rewards that came *after* it. A common strategy is to calculate the **return** (sum of future discounted rewards) for each time step. We then **normalize** these returns (subtract the mean, divide by std dev). This normalized score is called the **action advantage**. A positive advantage means the action was good, and a negative one means it was bad.\n",
        "> 3.  **Train (REINFORCE Algorithm):** We run a training step (like in supervised learning), but with a trick. We pretend the action the agent *actually* took was the \"correct\" one. But we modulate the loss. We multiply the loss by the action's **advantage**.\n",
        ">     -   If the advantage was **positive** (a good action), the gradients are applied as-is. This *increases* the probability of taking that action in the future (e.g., `y_target = 1 - action`).\n",
        ">     -   If the advantage was **negative** (a bad action), the gradients are *reversed*. This *decreases* the probability of taking that action in the future.\n",
        ">\n",
        "> This pushes the policy to take more actions that lead to high rewards and fewer actions that lead to low rewards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTOTqO5MvKqs"
      },
      "source": [
        "### Building the PG Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q9uZN8SvKqs",
        "outputId": "5db13fcf-d660-4e07-ae09-eaf9cca6be8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "n_inputs = 4 # == env.observation_space.shape[0]\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(5, activation=\"elu\", input_shape=[n_inputs]),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\"), # Outputs the probability of going left (action 0)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De7h7nvcvKqt"
      },
      "source": [
        "### Helper Functions for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "hlqYbo1_vKqt"
      },
      "outputs": [],
      "source": [
        "# This function plays one step in the environment.\n",
        "# It computes the gradients that would make the chosen action *more* likely.\n",
        "# We don't apply these gradients yet; we just return them.\n",
        "def play_one_step(env, obs, model, loss_fn):\n",
        "    with tf.GradientTape() as tape:\n",
        "        left_proba = model(obs[np.newaxis])\n",
        "        action = (tf.random.uniform([1, 1]) > left_proba) # Sample an action\n",
        "        y_target = tf.constant([[1.]]) - tf.cast(action, tf.float32) # The \"fake\" target\n",
        "        loss = tf.reduce_mean(loss_fn(y_target, left_proba))\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    obs, reward, done, info = env.step(int(action[0, 0].numpy()))\n",
        "    return obs, reward, done, grads\n",
        "\n",
        "# This function plays multiple full episodes and returns all rewards and gradients.\n",
        "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
        "    all_rewards = []\n",
        "    all_grads = []\n",
        "    for episode in range(n_episodes):\n",
        "        current_rewards = []\n",
        "        current_grads = []\n",
        "        obs = env.reset()\n",
        "        for step in range(n_max_steps):\n",
        "            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n",
        "            current_rewards.append(reward)\n",
        "            current_grads.append(grads)\n",
        "            if done:\n",
        "                break\n",
        "        all_rewards.append(current_rewards)\n",
        "        all_grads.append(current_grads)\n",
        "    return all_rewards, all_grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2el79ILOvKqt"
      },
      "outputs": [],
      "source": [
        "# This function computes the discounted returns and normalizes them.\n",
        "def discount_rewards(rewards, discount_factor):\n",
        "    discounted = np.array(rewards)\n",
        "    for step in range(len(rewards) - 2, -1, -1):\n",
        "        discounted[step] += discounted[step + 1] * discount_factor\n",
        "    return discounted\n",
        "\n",
        "def discount_and_normalize_rewards(all_rewards, discount_factor):\n",
        "    all_discounted_rewards = [discount_rewards(rewards, discount_factor)\n",
        "                              for rewards in all_rewards]\n",
        "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
        "    reward_mean = flat_rewards.mean()\n",
        "    reward_std = flat_rewards.std()\n",
        "    return [(discounted_rewards - reward_mean) / reward_std\n",
        "            for discounted_rewards in all_discounted_rewards]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEUK298NvKqt"
      },
      "source": [
        "### The Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Da1ESFvOvKqu"
      },
      "outputs": [],
      "source": [
        "n_iterations = 150\n",
        "n_episodes_per_update = 10\n",
        "n_max_steps = 200\n",
        "discount_factor = 0.95\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "loss_fn = keras.losses.binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "0RCiTF0wvKqu",
        "outputId": "bf20fae9-76cd-427f-c234-dfc6407ff155"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "tuple indices must be integers or slices, not NoneType",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-238408450.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# 1. Run & Collect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     all_rewards, all_grads = play_multiple_episodes(\n\u001b[0m\u001b[1;32m      4\u001b[0m         env, n_episodes_per_update, n_max_steps, model, loss_fn)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3340101326.py\u001b[0m in \u001b[0;36mplay_multiple_episodes\u001b[0;34m(env, n_episodes, n_max_steps, model, loss_fn)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_max_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mcurrent_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mcurrent_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3340101326.py\u001b[0m in \u001b[0;36mplay_one_step\u001b[0;34m(env, obs, model, loss_fn)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mleft_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mleft_proba\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Sample an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# The \"fake\" target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not NoneType"
          ]
        }
      ],
      "source": [
        "for iteration in range(n_iterations):\n",
        "    # 1. Run & Collect\n",
        "    all_rewards, all_grads = play_multiple_episodes(\n",
        "        env, n_episodes_per_update, n_max_steps, model, loss_fn)\n",
        "\n",
        "    # 2. Evaluate Actions\n",
        "    all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_factor)\n",
        "\n",
        "    all_mean_grads = []\n",
        "    for var_index in range(len(model.trainable_variables)):\n",
        "        # 3. Train (Modulate gradients)\n",
        "        # Multiply each gradient by its action's advantage (the final_reward)\n",
        "        mean_grads = tf.reduce_mean(\n",
        "            [final_reward * all_grads[episode_index][step][var_index]\n",
        "             for episode_index, final_rewards in enumerate(all_final_rewards)\n",
        "                 for step, final_reward in enumerate(final_rewards)], axis=0)\n",
        "        all_mean_grads.append(mean_grads)\n",
        "\n",
        "    # 3. Train (Apply gradients)\n",
        "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))\n",
        "\n",
        "    print(f\"Iteration: {iteration+1}/{n_iterations}, Mean Rewards: {np.mean([sum(rewards) for rewards in all_rewards])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INzU4sq3vKqu"
      },
      "source": [
        "## 3. Markov Decision Processes (MDPs)\n",
        "\n",
        "> **Theoretical Deep-Dive: MDPs, Value Iteration, and Q-Value Iteration**\n",
        ">\n",
        "> **MDPs** are the classic framework for RL problems. An MDP is defined by:\n",
        "> 1.  A set of **states** (s).\n",
        "> 2.  A set of **actions** (a).\n",
        "> 3.  **Transition probabilities** T(s, a, s'): the probability of moving from state `s` to state `s'` given action `a`.\n",
        "> 4.  **Rewards** R(s, a, s'): the reward received for this transition.\n",
        ">\n",
        "> The **Bellman Optimality Equation** provides a recursive definition of the optimal **state value** V*(s) (the expected return if the agent starts in state `s` and acts optimally forever after):\n",
        ">\n",
        "> $V^*(s) = \\max_{a} \\sum_{s'} T(s, a, s') [R(s, a, s') + \\gamma \\cdot V^*(s')]$\n",
        ">\n",
        "> This equation says: \"The optimal value of a state is the expected value of the best action you can take from it.\"\n",
        ">\n",
        "> This leads to the **Value Iteration** algorithm, which solves the equation iteratively.\n",
        ">\n",
        "> A more useful value is the **Q-Value** (or state-action value) Q(s, a), which is the expected return if the agent starts in state `s`, performs action `a`, and *then* acts optimally forever after. The **Q-Value Iteration** algorithm finds these optimal Q-Values:\n",
        ">\n",
        "> $Q_{k+1}(s, a) = \\sum_{s'} T(s, a, s') [R(s, a, s') + \\gamma \\cdot \\max_{a'} Q_k(s', a')]$\n",
        ">\n",
        "> Once you have the optimal Q-Values, the optimal policy $\\pi^*(s)$ is simply to choose the action with the highest Q-Value in that state: $\\pi^*(s) = \\argmax_{a} Q^*(s, a)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrgyG3DPvKqu"
      },
      "outputs": [],
      "source": [
        "# This is a small, simple MDP (from Figure 18-8 in the book)\n",
        "transition_probabilities = [ # shape=[s, a, s']\n",
        "    [[0.7, 0.3, 0.0], [1.0, 0.0, 0.0], [0.8, 0.2, 0.0]],\n",
        "    [[0.0, 1.0, 0.0], None, [0.0, 0.0, 1.0]],\n",
        "    [None, [0.8, 0.1, 0.1], None]]\n",
        "rewards = [ # shape=[s, a, s']\n",
        "    [[+10, 0, 0], [0, 0, 0], [0, 0, 0]],\n",
        "    [[0, 0, 0], [0, 0, 0], [0, 0, -50]],\n",
        "    [[0, 0, 0], [+40, 0, 0], [0, 0, 0]]]\n",
        "possible_actions = [[0, 1, 2], [0, 2], [1]]\n",
        "\n",
        "# Initialize Q-Values\n",
        "Q_values = np.full((3, 3), -np.inf) # -np.inf for impossible actions\n",
        "for state, actions in enumerate(possible_actions):\n",
        "    Q_values[state, actions] = 0.0  # for all possible actions\n",
        "\n",
        "# Run the Q-Value Iteration algorithm\n",
        "gamma = 0.90 # discount factor\n",
        "\n",
        "for iteration in range(50):\n",
        "    Q_prev = Q_values.copy()\n",
        "    for s in range(3):\n",
        "        for a in possible_actions[s]:\n",
        "            Q_values[s, a] = np.sum([\n",
        "                transition_probabilities[s][a][sp] *\n",
        "                (rewards[s][a][sp] + gamma * np.max(Q_prev[sp]))\n",
        "                for sp in range(3)])\n",
        "\n",
        "print(\"Final Q-Values:\\n\", Q_values)\n",
        "print(\"Optimal Policy (best action for each state):\", np.argmax(Q_values, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JkTlgwZvKqv"
      },
      "source": [
        "## 4. Q-Learning\n",
        "\n",
        "> **Theoretical Deep-Dive: Q-Learning (Off-Policy TD Learning)**\n",
        ">\n",
        "> The Q-Value Iteration algorithm assumes we *know* the transition probabilities (T) and rewards (R). This is almost never the case.\n",
        ">\n",
        "> **Q-Learning** is an algorithm that finds the optimal Q-Values *without* knowing T or R. It is a **Temporal Difference (TD) learning** algorithm, meaning it learns by observing transitions and rewards as they happen.\n",
        ">\n",
        "> The agent explores the environment (e.g., using an **$\\\\[Epsilon]$-greedy policy**). When it transitions from state `s` to `s'` by performing action `a` and receiving reward `r`, it updates the Q-Value for (s, a) using this update rule:\n",
        ">\n",
        "> $Q_{new}(s, a) = (1 - \\alpha) \\cdot Q_{old}(s, a) + \\alpha \\cdot (r + \\gamma \\cdot \\max_{a'} Q_{old}(s', a'))$\n",
        ">\n",
        "> -   $\\\\[Alpha]$ is the **learning rate**.\n",
        "> -   $(r + \\gamma \\cdot \\max_{a'} Q_{old}(s', a'))$ is the **TD Target**, or the *estimated* future value.\n",
        ">\n",
        "> In simple terms: we nudge the old Q-Value a little bit in the direction of our new, better estimate (the TD Target).\n",
        ">\n",
        "> Q-Learning is an **off-policy** algorithm because it learns about the *optimal* policy (the `max` part of the equation) regardless of what policy it is *actually* following to explore (e.g., the $\\\\[Epsilon]$-greedy policy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKWmQPWIvKqv"
      },
      "outputs": [],
      "source": [
        "# A simple exploration policy (random)\n",
        "def exploration_policy(state):\n",
        "    return np.random.choice(possible_actions[state])\n",
        "\n",
        "# Helper function to simulate a step\n",
        "def step(state, action):\n",
        "    probas = transition_probabilities[state][action]\n",
        "    next_state = np.random.choice([0, 1, 2], p=probas)\n",
        "    reward = rewards[state][action][next_state]\n",
        "    return next_state, reward\n",
        "\n",
        "# Reset Q-Values\n",
        "Q_values = np.full((3, 3), -np.inf)\n",
        "for state, actions in enumerate(possible_actions):\n",
        "    Q_values[state, actions] = 0.0\n",
        "\n",
        "alpha0 = 0.05 # initial learning rate\n",
        "decay = 0.005 # learning rate decay\n",
        "gamma = 0.90 # discount factor\n",
        "state = 0 # initial state\n",
        "\n",
        "for iteration in range(10000):\n",
        "    action = exploration_policy(state)\n",
        "    next_state, reward = step(state, action)\n",
        "    next_value = np.max(Q_values[next_state]) # This is the max_a' Q(s', a') part\n",
        "    alpha = alpha0 / (1 + iteration * decay)\n",
        "\n",
        "    # This is the Q-Learning update rule\n",
        "    Q_values[state, action] *= 1 - alpha\n",
        "    Q_values[state, action] += alpha * (reward + gamma * next_value)\n",
        "\n",
        "    state = next_state\n",
        "\n",
        "print(\"Final Q-Values (after 10,000 iterations):\\n\", Q_values)\n",
        "print(\"Optimal Policy (best action for each state):\", np.argmax(Q_values, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqMy6_hlvKqv"
      },
      "source": [
        "## 5. Deep Q-Learning (DQN)\n",
        "\n",
        "> **Theoretical Deep-Dive: Approximate Q-Learning**\n",
        ">\n",
        "> The Q-Learning algorithm requires a table to store the Q-Values for *every possible state-action pair*. This is impossible for complex problems like Atari games, where the number of states (pixel combinations) is astronomical.\n",
        ">\n",
        "> **Deep Q-Learning (DQN)** solves this. Instead of a Q-table, we use a **Deep Q-Network (DQN)** to *approximate* the Q-Values. This network takes a state (e.g., a stack of game frames) as input and outputs an estimated Q-Value for *every possible action* in that state.\n",
        ">\n",
        "> **Experience Replay:** To train the DQN, we use an **Experience Replay Buffer (or Replay Memory)**. This is a `deque` (a fast list-like structure) that stores the agent's experiences (transitions) as tuples: `(state, action, reward, next_state, done)`.\n",
        "> At each training step, we sample a random batch of experiences from this buffer. This breaks the temporal correlation between consecutive experiences, which is critical for stabilizing DQN training.\n",
        ">\n",
        "> **Fixed Q-Value Targets (Target Network):** A regular DQN is unstable because its own predictions are used to define its targets (it's \"chasing its own tail\"). To fix this, we use *two* DQNs:\n",
        "> 1.  The **Online Model:** This is the model we train at every step. It is used to choose actions (the `max_a'` part of the Bellman equation).\n",
        "> 2.  The **Target Model:** This is a clone of the online model. It is used to *calculate* the target Q-Values. Its weights are frozen for many steps and only updated (by copying the online model's weights) periodically. This provides stable targets for the online model to learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIXlQvokvKqv"
      },
      "source": [
        "### Creating the Deep Q-Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GMGLoA4vKqw",
        "outputId": "f02c45a5-4244-4d24-a437-d46cee59d441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v0\", render_mode=\"rgb_array\") # Specify render_mode for gymnasium\n",
        "input_shape = [4] # == env.observation_space.shape\n",
        "n_outputs = 2 # == env.action_space.n\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(32, activation=\"elu\", input_shape=input_shape),\n",
        "    keras.layers.Dense(32, activation=\"elu\"),\n",
        "    keras.layers.Dense(n_outputs)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqi9i0WuvKqw"
      },
      "source": [
        "### Helper Functions for DQN\n",
        "\n",
        "We need an $\\\\[Epsilon]$-greedy policy, a replay buffer, and a function to sample from it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ioVA4tWHvKqw"
      },
      "outputs": [],
      "source": [
        "def epsilon_greedy_policy(state, epsilon=0):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.randint(n_outputs) # Explore\n",
        "    else:\n",
        "        Q_values = model.predict(state[np.newaxis], verbose=0) # Added verbose=0 to suppress Keras output\n",
        "        return np.argmax(Q_values[0]) # Exploit\n",
        "\n",
        "from collections import deque\n",
        "replay_buffer = deque(maxlen=2000)\n",
        "\n",
        "def sample_experiences(batch_size):\n",
        "    indices = np.random.randint(len(replay_buffer), size=batch_size)\n",
        "    batch = [replay_buffer[index] for index in indices]\n",
        "    states, actions, rewards, next_states, dones = [\n",
        "        np.array([experience[field_index] for experience in batch])\n",
        "        for field_index in range(5)\n",
        "    ]\n",
        "    return states, actions, rewards, next_states, dones\n",
        "\n",
        "def play_one_step(env, state, epsilon):\n",
        "    action = epsilon_greedy_policy(state, epsilon)\n",
        "    # gymnasium step returns (observation, reward, terminated, truncated, info)\n",
        "    next_state, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated # Combine for replay buffer\n",
        "    replay_buffer.append((state, action, reward, next_state, done))\n",
        "    return next_state, reward, done, info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtaI03VZvKqw"
      },
      "source": [
        "### DQN Training Step\n",
        "\n",
        "This is the core of the DQN algorithm. We use the **Double DQN** and **Fixed Q-Value Targets** logic from the book (which are key improvements over the original DQN)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "giInw8DVvKqx",
        "outputId": "19a09f87-7c63-4bfa-c837-66c2a13a7356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 50, Mean Rewards: 22.24\n",
            "Episode: 100, Mean Rewards: 22.4\n",
            "Episode: 150, Mean Rewards: 20.74\n",
            "Episode: 200, Mean Rewards: 17.1\n",
            "Episode: 250, Mean Rewards: 15.76\n",
            "Episode: 300, Mean Rewards: 17.98\n",
            "Episode: 350, Mean Rewards: 13.08\n",
            "Episode: 400, Mean Rewards: 11.1\n",
            "Episode: 450, Mean Rewards: 11.12\n",
            "Episode: 500, Mean Rewards: 19.68\n",
            "Episode: 550, Mean Rewards: 29.24\n",
            "Episode: 600, Mean Rewards: 42.54\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "batch_size = 32\n",
        "discount_factor = 0.95\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# Create the target network\n",
        "target = keras.models.clone_model(model)\n",
        "target.set_weights(model.get_weights())\n",
        "\n",
        "def training_step(batch_size):\n",
        "    experiences = sample_experiences(batch_size)\n",
        "    states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "    # Double DQN logic:\n",
        "    # 1. Use the *online* model to pick the best *action* for the next state\n",
        "    next_Q_values = model.predict(next_states, verbose=0)\n",
        "    best_next_actions = np.argmax(next_Q_values, axis=1)\n",
        "\n",
        "    # 2. Use the *target* model to get the Q-Value for that chosen action\n",
        "    next_mask = tf.one_hot(best_next_actions, n_outputs).numpy()\n",
        "    next_best_Q_values = (target.predict(next_states, verbose=0) * next_mask).sum(axis=1)\n",
        "\n",
        "    # 3. Compute the target Q-Value\n",
        "    # If done=True (1.0), the future reward is 0. If done=False (0.0), we add the future reward.\n",
        "    target_Q_values = (rewards +\n",
        "                       (1 - dones) * discount_factor * next_best_Q_values)\n",
        "    target_Q_values = target_Q_values.reshape(-1, 1)\n",
        "\n",
        "    # 4. Train the *online* model to predict these target Q-Values\n",
        "    mask = tf.one_hot(actions, n_outputs)\n",
        "    with tf.GradientTape() as tape:\n",
        "        all_Q_values = model(states)\n",
        "        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n",
        "        loss = tf.reduce_mean(loss_fn(target_Q_values, Q_values))\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "episode_rewards_list = []\n",
        "\n",
        "for episode in range(600):\n",
        "    obs, info = env.reset() # gymnasium reset returns (observation, info)\n",
        "    episode_rewards = 0\n",
        "    for step in range(200):\n",
        "        # Epsilon decays from 1.0 down to 0.01 over 500 episodes\n",
        "        epsilon = max(1 - episode / 500, 0.01)\n",
        "        obs, reward, done, info = play_one_step(env, obs, epsilon)\n",
        "        episode_rewards += reward\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    episode_rewards_list.append(episode_rewards)\n",
        "    if (episode + 1) % 50 == 0:\n",
        "        print(f\"Episode: {episode + 1}, Mean Rewards: {np.mean(episode_rewards_list[-50:])}\")\n",
        "\n",
        "    if episode >= 50: # Changed from > 50 to >= 50 to start training earlier\n",
        "        training_step(batch_size)\n",
        "        if episode % 50 == 0: # Update target network every 50 episodes\n",
        "            target.set_weights(model.get_weights())\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(episode_rewards_list)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Sum of Rewards\")\n",
        "plt.title(\"DQN Training on CartPole\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DTEeg0dvKqx"
      },
      "source": [
        "## 6. The TF-Agents Library\n",
        "\n",
        "Implementing all the DQN improvements (Double, Dueling, Prioritized Replay) is complex. The **TF-Agents** library provides robust, well-tested implementations of these algorithms and more.\n",
        "\n",
        "> **Theoretical Deep-Dive: TF-Agents Architecture**\n",
        ">\n",
        "> TF-Agents has a clear, modular architecture:\n",
        "> 1.  **Environments:** Wraps Gym environments (e.g., `suite_gym.load()`). `TFPyEnvironment` makes them usable by TensorFlow.\n",
        "> 2.  **Networks:** The policy/Q-networks (e.g., `QNetwork`).\n",
        "> 3.  **Agents:** The \"brain\" that holds the network and the learning algorithm (e.g., `DqnAgent`). The agent has a `collect_policy` (for exploration) and a `policy` (for evaluation).\n",
        "> 4.  **Replay Buffers:** Stores trajectories (e.g., `TFUniformReplayBuffer`).\n",
        "> 5.  **Drivers:** The `DynamicStepDriver` is the \"worker\" that uses the `collect_policy` to play in the environment and sends the collected trajectories to an `observer` (like the replay buffer).\n",
        "> 6.  **Dataset:** The `replay_buffer.as_dataset()` method creates a `tf.data.Dataset` to efficiently sample batches for training.\n",
        "> 7.  **Training:** The `agent.train()` method pulls a batch from the dataset and runs one training step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOw7IC8RvKqx"
      },
      "source": [
        "### Setting up the Environment and Wrappers\n",
        "\n",
        "We will train an agent to play the Atari game Breakout. We need to load the environment with several wrappers:\n",
        "-   `AtariPreprocessing`: Converts the image to grayscale, downsamples it, and stacks the last 4 frames (to give the agent a sense of motion).\n",
        "-   `FrameStack4`: Stacks 4 consecutive frames into one observation.\n",
        "-   `TFPyEnvironment`: Makes the Gym environment usable by TF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "YEAHPuiLvKqx"
      },
      "outputs": [],
      "source": [
        "# from tf_agents.environments import suite_gym\n",
        "# from tf_agents.environments.atari_preprocessing import AtariPreprocessing\n",
        "# from tf_agents.environments.atari_wrappers import FrameStack4\n",
        "# from tf_agents.environments.tf_py_environment import TFPyEnvironment\n",
        "# from tf_agents.networks.q_network import QNetwork\n",
        "# The tf-agents library is currently encountering installation issues. Skipping relevant imports for now.\n",
        "# from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
        "# from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "# from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
        "# from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
        "# # from tf_agents.utils import common\n",
        "\n",
        "max_episode_steps = 27000 # 108k ALE frames (1 step = 4 frames)\n",
        "environment_name = \"BreakoutNoFrameskip-v4\"\n",
        "\n",
        "# Load the base Gym env, suite_gym.load automatically handles gymnasium if installed\n",
        "# This section also relies on tf-agents imports that are currently commented out.\n",
        "# env = suite_gym.load(\n",
        "#     environment_name,\n",
        "#     max_episode_steps=max_episode_steps,\n",
        "#     gym_env_wrappers=[AtariPreprocessing, FrameStack4])\n",
        "\n",
        "# # Wrap it in a TF-Agents environment\n",
        "# tf_env = TFPyEnvironment(env)\n",
        "\n",
        "# print(\"Observation Spec:\", tf_env.observation_spec())\n",
        "# print(\"Action Spec:\", tf_env.action_spec())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC2Jok-3vKqy"
      },
      "source": [
        "### 1. Creating the Deep Q-Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CT4hINaSvKqy",
        "outputId": "fe99c333-0202-4da7-96c1-51906d2f6ea9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'QNetwork' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3605365287.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfc_layer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m q_net = QNetwork(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtf_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtf_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'QNetwork' is not defined"
          ]
        }
      ],
      "source": [
        "# # Preprocessing layer to normalize pixels\n",
        "# preprocessing_layer = keras.layers.Lambda(\n",
        "#     lambda obs: tf.cast(obs, np.float32) / 255.)\n",
        "\n",
        "# # Convolutional layers as defined in the 2015 DQN paper\n",
        "# conv_layer_params=[(32, (8, 8), 4), (64, (4, 4), 2), (64, (3, 3), 1)]\n",
        "# fc_layer_params=[512]\n",
        "\n",
        "# q_net = QNetwork(\n",
        "#     tf_env.observation_spec(),\n",
        "#     tf_env.action_spec(),\n",
        "#     preprocessing_layers=preprocessing_layer,\n",
        "#     conv_layer_params=conv_layer_params,\n",
        "#     fc_layer_params=fc_layer_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbYY5jadvKqy"
      },
      "source": [
        "### 2. Creating the DQN Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "WRM_TvfPvKqy"
      },
      "outputs": [],
      "source": [
        "train_step = tf.Variable(0)\n",
        "update_period = 4 # Train the model every 4 steps\n",
        "\n",
        "# Use the same optimizer parameters as the 2015 DQN paper\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=2.5e-4, rho=0.95, momentum=0.0,\n",
        "                                     epsilon=0.00001, centered=True)\n",
        "\n",
        "# Epsilon decays from 1.0 to 0.01 over 1 million ALE frames (250k steps)\n",
        "epsilon_fn = keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate=1.0,\n",
        "    decay_steps=250000 // update_period,\n",
        "    end_learning_rate=0.01)\n",
        "\n",
        "# The tf-agents agent relies on tf-agents library, which is failing to install.\n",
        "# Skipping this agent creation for now.\n",
        "# agent = DqnAgent(\n",
        "#     tf_env.time_step_spec(),\n",
        "#     tf_env.action_spec(),\n",
        "#     q_network=q_net,\n",
        "#     optimizer=optimizer,\n",
        "#     target_update_period=2000, # 8k steps = 32k ALE frames\n",
        "#     td_errors_loss_fn=keras.losses.Huber(reduction=\"none\"),\n",
        "#     gamma=0.99, # Discount factor\n",
        "#     train_step_counter=train_step,\n",
        "#     epsilon_greedy=lambda: epsilon_fn(train_step))\n",
        "\n",
        "# agent.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xar83-ZvKq3"
      },
      "source": [
        "### 3. Creating the Replay Buffer and Observer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "PVLSX8ukvKq3"
      },
      "outputs": [],
      "source": [
        "# # The replay buffer relies on agent.collect_data_spec, which is part of the tf-agents setup, currently commented out.\n",
        "# replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "#     data_spec=agent.collect_data_spec,\n",
        "#     batch_size=tf_env.batch_size,\n",
        "#     max_length=1000000) # 1 million experiences\n",
        "\n",
        "# # The observer is a function that adds a trajectory to the replay buffer\n",
        "# replay_buffer_observer = replay_buffer.add_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI_Rw8WOvKq3"
      },
      "source": [
        "### 4. Creating the Training Metrics and Collect Driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Jap5iYbjvKq4"
      },
      "outputs": [],
      "source": [
        "# The training metrics and collect driver rely on tf-agents components, currently commented out.\n",
        "# from tf_agents.metrics import tf_metrics\n",
        "\n",
        "# train_metrics = [\n",
        "#     tf_metrics.NumberOfEpisodes(),\n",
        "#     tf_metrics.EnvironmentSteps(),\n",
        "#     tf_metrics.AverageReturnMetric(),\n",
        "#     tf_agents.metrics.AverageEpisodeLengthMetric(),\n",
        "# ]\n",
        "\n",
        "# # The collect driver uses the agent's 'collect_policy' (which is epsilon-greedy)\n",
        "# collect_driver = DynamicStepDriver(\n",
        "#     tf_env,\n",
        "#     agent.collect_policy,\n",
        "#     observers=[replay_buffer_observer] + train_metrics,\n",
        "#     num_steps=update_period) # Collect 4 steps at a time\n",
        "\n",
        "# # We also create a separate driver with a *random* policy to pre-fill the buffer\n",
        "# initial_collect_policy = RandomTFPolicy(tf_env.time_step_spec(),\n",
        "#                                           tf_env.action_spec())\n",
        "# init_driver = DynamicStepDriver(\n",
        "#     tf_env,\n",
        "#     initial_collect_policy,\n",
        "#     observers=[replay_buffer.add_batch],\n",
        "#     num_steps=20000) # 20k steps = 80k ALE frames\n",
        "\n",
        "# print(\"Populating Replay Buffer...\")\n",
        "# init_driver.run() # This will take a moment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpMMoryOvKq4"
      },
      "source": [
        "### 5. Creating the Dataset and Training Loop\n",
        "\n",
        "We use `as_dataset()` to create a `tf.data.Dataset` that efficiently samples batches of 2-step trajectories from the buffer. This is what the `agent.train()` method will consume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Bsyx4KWrvKq4"
      },
      "outputs": [],
      "source": [
        "# The dataset creation relies on the replay_buffer, which is part of the tf-agents setup, currently commented out.\n",
        "# # Sample 64 trajectories, each 2 steps long (1 transition)\n",
        "# dataset = replay_buffer.as_dataset(\n",
        "#     sample_batch_size=64,\n",
        "#     num_steps=2,\n",
        "#     num_parallel_calls=3).prefetch(3)\n",
        "\n",
        "# iterator = iter(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "bGvtu5gHvKq4"
      },
      "outputs": [],
      "source": [
        "# The training loop relies on tf-agents components like collect_driver, agent, and dataset, currently commented out.\n",
        "# # Convert the main functions to TF Functions for speed\n",
        "# collect_driver.run = common.function(collect_driver.run)\n",
        "# agent.train = common.function(agent.train)\n",
        "\n",
        "# def train_agent(n_iterations):\n",
        "#     time_step = None\n",
        "#     policy_state = agent.collect_policy.get_initial_state(tf_env.batch_size)\n",
        "#     iterator = iter(dataset)\n",
        "\n",
        "#     for iteration in range(n_iterations):\n",
        "#         # 1. Collect experience\n",
        "#         time_step, policy_state = collect_driver.run(time_step, policy_state)\n",
        "\n",
        "#         # 2. Sample a batch from the buffer\n",
        "#         trajectories, buffer_info = next(iterator)\n",
        "\n",
        "#         # 3. Train the agent on that batch\n",
        "#         train_loss = agent.train(trajectories)\n",
        "\n",
        "#         if iteration % 1000 == 0:\n",
        "#             print(f\"\\rIteration: {iteration}, Loss: {train_loss.loss.numpy():.5f}\")\n",
        "#             # You could also log metrics here\n",
        "\n",
        "# # Let's train for a few steps to see it working.\n",
        "# # A full training run would be 250,000+ iterations.\n",
        "# print(\"Starting training...\")\n",
        "# train_agent(n_iterations=2000)\n",
        "# print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCOvvGMovKq4"
      },
      "source": [
        "## 7. Overview of Popular RL Algorithms\n",
        "\n",
        "> **Theoretical Deep-Dive:**\n",
        ">\n",
        "> -   **Actor-Critic (A3C/A2C):** Combines Policy Gradients and DQNs. An **Actor** (the policy) decides which action to take, and a **Critic** (the Q-Network) evaluates how good that action was. The Critic's evaluation is used to train the Actor, which is much more efficient than the PG (REINFORCE) method.\n",
        "> -   **Proximal Policy Optimization (PPO):** A more recent Policy Gradient algorithm from OpenAI that is more stable and less complex than its predecessors. It works by clipping the loss function to prevent destructively large policy updates.\n",
        "> -   **Soft Actor-Critic (SAC):** A modern off-policy algorithm that learns to maximize not only the reward but also the **entropy** of its actions. This encourages exploration and leads to very stable and efficient learning."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}